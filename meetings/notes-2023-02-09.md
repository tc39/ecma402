# 2023-02-09 ECMA-402 Meeting
## Logistics

### Attendees

- Shane Carr - Google i18n (SFC), Co-Moderator
- Daniel Minor - Mozilla (DLM)
- Romulo Cintra - Igalia (RCA)
- Henri Sivonen - Mozilla (HJS)
- Richard Gibson - OpenJS Foundation (RGN)
- Frank Yung-Fong Tang - Google i18n, V8 (FYT)
- Ben Allen - Igalia (BAN)
- Eemeli Aro - Mozilla (EAO)
- Yusuke Suzuki - Apple (YSZ)
- Louis-Aimé de Fouquières - Invited Expert (LAF)
- Zibi Braniecki - Mozilla (ZB)
- Markus Scherer - Google (MWS)

### Standing items

- [Discussion Board](https://github.com/tc39/ecma402/projects/2)
- [Status Wiki](https://github.com/tc39/ecma402/wiki/Proposal-and-PR-Progress-Tracking) -- please update!
- [Abbreviations](https://github.com/tc39/notes/blob/master/delegates.txt)
- [MDN Tracking](https://github.com/tc39/ecma402-mdn)
- [Meeting Calendar](https://calendar.google.com/calendar/embed?src=unicode.org_nubvqveeeol570uuu7kri513vc%40group.calendar.google.com)
- [Matrix](https://matrix.to/#/#tc39-ecma402:matrix.org)

## Status Updates

### Editor's Update

USA : We got TG1 consensus on Normative PR, and few editorial improvements landing in the upcoming weeks, NFv3 going for Stage 4 and DurationFormat updates 

RGN: Additionally we've made changes about how we reference Unicode documents, our contribution guidelines, etc. And ideally before next meeting I'd like to see the locale handling land as well.

### MessageFormat Working Group

EAO: We managed to merge a section on error handling. It influences what the Intl MessageFormat API may look like. Currently, if you try to format something that doesn't work, you get an exception. But now we return an approximation of the best-attempt, and use a side channel to return the error.

Any comments?

EAO: Next, one of the current topics we’ve been discussing is the description of the formatters that are built in and how they’re described. How much alignment are we looking for between implementations. This is an active issue we’re discussing and will continue to discuss it. The big question is: how much shared surface is desired between the different implementations. A key issue here that should be highlighted is that ICU formatters work using a skeleton string while we prefer options bags. If possible, we want to avoid adding explicit public support for JavaScript. This should be a doable thing but I’d like to highlight this here to get the temperature of the room.

USA: I have an affirming statement. I've been trying to understand the use cases at Bloomberg for i18n. They heavily rely on skeletons in their existing infrastructure. We don't support those in ECMAScript, which is by-design. Designing for JavaScript developers who don’t have significant experience with i18n. Prefer much more the design using options bags – a big set of knobs you can turn, MessageFormat can get complicated

SFC: I have a question to either USA or EAO… skeleton strings are convertible to options bags. But not pattern strings. Which one are we needing?

USA: to clarify the Bloomberg position, they do need skeleton strings, because they have all of this financial information, their API is different, the options bag mental model has existed in ways across JavaScript, replicated in the Temporal proposal, more natural way to get them started with i18n

EAO: Just to clarify, in the absence of any support for skeleton strings in JavaScript, I’d choose to keep working on bringing MessageFormat to JS without skeleton strings.

SFC: To clarify with Ujjwal, if any client (Bloomberg here) we should be able to support them as options bags and skeleton strings are one-to-one convertible

USA: I did feel going through their use cases that it was not a standard i18n use case that doesn’t match with majority of user base, more niche, understandable if they have to jump through a few hoops to convert skeleton strings into options bags or vice-versa. It doesn’t make sense for the new to i18n that we’ve catered to so far

EAO: Ujjwal, if you’re interested I’ve got two libraries to convert date/time skeleton strings to options bags

### Governance Issue

USA: TC39-TG1 has professional stenography since last plenary. We've over time been taking notes in our own fashion here in TG2. What do we think about potentially submitting a request on behalf of TG2 to extend that to the TG2 meetings?

SFC: We have the same problem as TG1 that a vast majority of the notes are taken by a minority of attendees. Stenography is a good option to work around that. This meeting is 2.5 hours every month as opposed to the 4 day long, every-two-months TG1 meeting. Our note-taking has not been as “broken” so I think we could do just fine either way. I’d leave this to Igalians to choose if this is something worth investigating.

YSZ: For stenography, as the Apple rep, I'd need to have a discussion with our team to see if it is in policy.

DLM: I'd like to voice general support for stenography. Having stenography support means that more people can participate. It also alleviates guilt from folks unable to take notes.

USA: What I conclude here is that we’re generally positive about stenography, we could continue to see as the stenographer continues to make progress/improvements over time at TC39 plenary. Over time we could form a more conclusive position, but I do concur with the general idea that we have less of a problem than plenary, in general it’s a better environment for notetakers. 

DLM: A follow-up question. In TC39 we've discussed why making a recording of the meeting isn't an alternative. Do those same concerns apply here?

USA: TC39 isn’t recorded because certain delegates have reservations. We might be in a similar situation where not everyone is at complete liberty to be recorded. Perhaps we could try to work out some way to do recordings in a way that doesn’t violate Apple guidelines. We might have to cross that bridge in the greater TC39 context, perhaps good idea to wait for that conversation to happen again there, then re-open it here

SFC: One of the primary use cases for recording notes for meetings here is that we can accommodate people who are unable to attend this meeting on a regular basis to make sure they stay in the loop, not practical to tell these people to go watch a long mpeg file. People do read and care about these notes, so I don’t necessarily want to change this medium. A recording in addition to notes is more of a policy question. 

USA: I want to first concur – we can go back and edit notes, we can summarize notes, we can search notes – so there’s definitely that aspect of notes. In favor of videos: argument from ECMA was that to take a secure recording of the meeting, using this recording to asynchronously make notes, not necessarily publishing the video / keeping it safely on ECMA servers or getting rid of them after two week mark. Complex discussion: more easy discussion is whether we’re happy with the notes / need help from stenographers.

DLM: I general the notes are super useful for us at Mozilla, since we have internal meetings where we discuss proposals, very useful to look back and see positions taken on proposals in the past. Very in favor of notes.

YSZ: I queried about Apple's policy on stenography on standard meeting, and I got the response that, "stenography is allowed as long as it is done by human (not machine)". So, if the proposal is having professional human stenography, then it is 100% fine with us :)

### Proposal Status Changes

https://github.com/tc39/ecma402/wiki/Proposal-and-PR-Progress-Tracking




## Pull Requests

### Normative: Integrate Intl NumberFormat v3 into ECMA-402 #753

https://github.com/tc39/ecma402/pull/753

SFC: Stage 4 PR for NumberFormat-v3. No normative changes, solely editorial.

#### Conclusion

Waiting for reviews, hopefully landing on time for next edition

### Editorial: Align locale handling with UTS 35 #735

https://github.com/tc39/ecma402/pull/735

RGN: Would appreciate implementor reviews

#### Conclusion

Hopefully land in 2023 edition

### Normative: Stage4 PR for proposal-intl-enumeration #716

https://github.com/tc39/ecma402/pull/716
#### Conclusion

Hopefully land in 2023 edition

## Proposals and Discussion Topics

### What should happen with the usage: "sort" vs "search" choice in implementations? #256

https://github.com/tc39/ecma402/issues/256


HJS: ECMA-402 doesn’t have a search API, has mechanism for loading search data, doesn’t have API to go with that. I don’t see anyone answering how we use the search data for searching. Assuming we don’t want to have quadratic behavior, with the API surface available what do you do with search data? Hypothesis: this is a historical document of how the spec was written before my time. I’m not advocating as a search API – very skeptical of using collator for search.

If there isn’t a use case for this search data in the context of the sorting-oriented API, the reasonable step would be to not have the search data in Firefox. What have I missed about the history and use cases, why is there this API surface for requesting search data to be loaded, is there a use case for it? 

FYT: I don't understand why you say there's no search API. But all the search is based on comparison. The collator has a compare function. You can't implement a search algorithm without comparing a string.

HJS: In order to use that API for search, how would I go about it? I have a haystack and a needle. I would start from index 0 in the haystack and see if the needle fits there. But what substring of the haystack do I compare with the needle?

FYT: We're thinking about different types of search. Say I have a phonebook. It has first name and last name, or diacritic marks, or uppercase/lowercase. I can basically do a binary search on that.

HJS: In that case, the user would need to write the entire first name or last name for that use case to make sense.

FYT: The search is not searching inside the string; it's about searching of string data.

HJS: Is it known if this use case is common enough to be worth this much data? What happens if you use non-search data for this use case? What does the search data actually do? In the root, AFAICT, the main differences are in Hangul, where it allows an archaic Hangul haystack to be searched by a modern Hangul string. That sort of thing is very niche in itself. And as a phonebook, that seems unlikely to show up. There's also a performance optimization. If you just care about German, not Korean search for German locale, same as phonebook. Apple wanting to use old-school matching for search in Finnish and Swedish. Overall when you are matching the whole string, when would it make a difference that we have a search collation, except for German to have the phonebook collation and two very narrow Korean cases (search is archaic on the one hand, or phonebook-specific thing). For a WebAPI, how often do people write an app like a contacts app for a phone?

FYT: I think talking about probability is a very scary thing, the probability of a particular locale is relatively small – but if (for example) in Finland, people care about that locale. You have a concern about pre-existing ECMA-402 data, want to trim it out in order to have a smaller implementation. 

In clause 9.1, it explicitly mentions that the sort and search locale data are implementation-dependent. It's also in 10.2.3. It has an explicit clause that the data are implementation-defined within the current constraints. Instead of saying “should we remove the ability from the standard,” the standard already provides an implementation to not use the whole thing.

HJS: I’m not arguing that any specific language is rare, in Firefox we do not trim any languages away from CLDR data set.

FYT: When we talk about how likely a feature is to be used, we have to be very careful about that framework – if we apply the framework in terms of “the percentage of people using it are very small’, we could end up using that to say “well that locale doesn’t need to be there.” The probability of people using it is not a good criterion here. A proper place to discuss is probably not here, but rather in CLDR. Not saying your concern is not valid, but that might be a better place to get a more concrete issue.

HJS: A couple things. First, for use cases, is it sufficiently niche? Regardless of locale, is the thing where you search from a list of strings where the thing you're searching for is an exact match of a list item, as opposed to being a substring of something… how often does that happen? And the next step is, for that case where you have the entire string matching, is that sort versus search data different for that use case? If I go to CLDR, it's clear that this search collation data is relevant for the subtring search API. Since there is no substring search API here, what does substring search do? How much more benefit do we get from matching from a list vs. using a sort and matching from the list with that sort of collation data. The difference there seems very hard to justify the amount of data. If others have use cases I’d like to hear them – not asking for a spec change, asking to understand the history of the usage parameter

YSZ: If you think this data is not used, the appropriate venue is CLDR not ECMA-402

HJS: ICU4C does have API surface that makes use of that data, doesn’t make sense to ask for it to be dropped from CLDR, question is does it make sense for us in Firefox (when we are not using it for substring search) and there is no web API that uses that data for substring search, is there a use case that justifies that data being around when the API is a sorting API rather than a searching API. Although, as noted, it can be used for searching list items if the needle is a full match rather than a substring. 

SFC: I think the main issue here is that when collator was added into ECMA-402 we included that the source collations variants would be accessible via the API, is it worth the extra payload to not just use the regular collations rather than the search collations – is that fine, or is that going to break anything?

FYT: In ICU4C there is some other search, but in ECMA-402 the only API is compare-string. It's not clear if the search variant is useful there.

MWS: The difference between regular and search collation data is that the regular collation data is designed for comparison. So it gives a fine-grained result. The search tailorings we have are not designed for less-than or greater-than; they're designed for equality questions. They're specifically constructed to match people's expectations on matching behavior, how they expect to find things, rather than giving an order. A lot of the time there's not much difference between the orderings, except that the search collation doesn't care about ordering. But there are sometimes special cases added into the search collations for finding things. Chrome uses collation-based search, for example, and Chrome uses the search tailorings. Jungshik worked on that.

HJS: Both Chrome and Safari use collator-based ctrl-F, they have reasons to have that data around, we don’t.

MWS: So in terms of use case for this API, I would tend to agree with HJS in that it's a little weak to say you need the dat when the API only meaningfully lets you do a whole-string match, not a substring match.

SFC: Followup question: is it reasonable behavior for an implementation like Firefox to just return the regular collations when the search collations are requested. If it’s the case that the search isn’t that useful, is it a reasonable idea (and appears to be spec-compliant) to just return the same rules and ignore that option 

MWS: It would be a fallback that would be functional, in a lot of cases the difference for testing equality for strings will be relatively small except for cases where there are special search tailorings that are a little bit different. For a lot of languages the difference would be insignificant. If someone does care about that difference, it may be reasonable to get an error, but on average that would be unfriendly 

HJS: If I can imagine cases where someone would misuse the search collations for search, it may be when someone requests search when they should be using phonebook. Only languages where the difference is meaningful are Finnish, Swedish, Korean (archaic Hangul), Catalan… In Catalan, it's about how "l." behaves. In German it's about "ue". Sort collation (except for German) returns the phonebook. From what it sounds like, if we put this in Firefox the chances are that people aren’t going to notice. I have not seen uses of this thing so far. The most obvious thing that people do know is the German thing, but I have a hack for that that seems like it could work. 

MWS: One thing is to point out that since the search collations are designed for equality, not order, if someone creates a search collator and expects a certain order, the results could be different, but that would be an abuse of asking for the search collator and then expecting a certain order out of it.

HJS: That’s the webcompat risk here, if it’s actually used for sorting. This discussion gave me a use case that I didn’t think about, the thing when you use it for searching for a list of full matches rather than substring, but it sounds like overall there isn’t a clear use case that I’ve missed. 

SFC: We have issue 256 open here, we want to make sure we understand what the action here – is there any change that we need to make to the ECMA-402 specification. If so, we should list exactly what should be done, otherwise we should resolve it. 

HJS: So far what I’ve seen is that people notice that there is an API surface for search vs. sort, they find out what it does makes German different, they make a test case for it, can’t say what use case that serves other than “test that the API does what it does” without a use case.

SFC: As a group can we establish that we don’t care if there’s a difference in behavior and that therefore there does not need to be any testing added for it? In which case I can close 256 with that conclusion and refer to the meeting notes for today. 

FYT: Question: should we add an isEqual API to collator that only returns a boolean to make the search meaningful

SFC: You can do compare equals 0

FYT: Returns 3 possible values, could be abused

MWS: Using a convenience wrapper doesn’t prevent misuse

FYT: Currently no correct one to call
 
MWS: Different options for if you can expand/shrink a substring [...] don’t know if people want an ECMAScript API for that

HJS: I think we shouldn't add more API. I don't want to provoke this question because I don't want that API. I would rather drop the data than add a new API for it. I'm concerned about the data because of how Ctrl-F works in Firefox, which is faster than Chrome or Safari. If there were an API to do locale-aware accent-ignoring search, where it normalizes some diacritics but not others, how much data would you need, assuming you have the UCD and normalization data, I think it would be possible to have it with less data, than starting from the observation that we could start with collator. Would like to avoid the conclusion that because there is data we should add API. Instead: do people have actual requests for the API / demand for the API, and if so what should it be backed by?

SFC: I’d like to record a conclusion. 1: we expect that it’s okay for implementations to differ. 2: Ideally we should document this in prose (either in the spec or MDN) on what this is used for. Currently on MDN: usage: “search” and “sort” are two options, maybe add a few sentences documenting this. 

BAN: +1

MWS: +1

EAO: +1 on not caring about potential differences

YSZ: +1. This is basically the same to modifying CLDR data of "search" to make it exact same to "sort", and CLDR customization should be allowed.

LAF: +1 on Shane's proposal

RCA: +1 Ok

#### Conclusion

Proceed as SFC suggested above.

### User Preferences #580 and #409

RCA: Two main issues identified in last meeting: 1: sequence of what we’re doing – we’re trying to just return explicitly the values that were changed by the user, decided to 1st check all values that user has on the system, check if there’s privacy settings, return values to user. 2: Research possibilities of having separate buckets of information. We identified two clear buckets based on the preferences that we had on the initial proposal. We decided to have Date/Time and Language/Region as separate buckets, have client hints for Locale-Preferences-LanguageRegion. Something similar in JavaScript API, but most important part of discussion is what the room feels about these buckets – start with this division? Does this to some extent remove fingerprinting vectors? 

FYT: Sec-CH is part of which spec? 

RCA: Started with user-locale-client-hints proposal, it’s a work in progress. 

FYT: Is client hint WICG or IETF? 

USA: WICG

RCA: We’ve also opened the issue there. The main discussion we should have is if we are in a good direction (preferences in two buckets). Is this something implementable / sort out the main contention with fingerprinting. 

HJS: Would there be some kind of browser level preference (“check this box to honor system-level preferences”), otherwise action at a distance: could this allow for fingerprinting even if the user preference doesn’t directly refer to the web.

RCA: Depends on each browser. The browsers that have Client-Hints… the mechanism is already implicit in how it works. For other browsers, it depends on how they choose to expose these preferences or not.

HJS: If it’s not a preference, would it be part of the Chrome concept of high-entropy values for client hints? Chrome has does a reduction of user-preferred languages. Historically logic was that since it was exposed over HTTP that it was therefore acceptable to expose via JavaScript. Chrome is now only using most-preferred language rather than complete list of language preferences in order to reduce fingerprinting possibility. Tradeoff: internationalization vs. privacy. 

USA: To address that, I think that since the beginning of this work we’ve put in a number of countermeasures that would limit the usefulness of this for fingerprinting. Make them client hints so that they’re all fully optional, possible discussion of what the user consent flow should be. One extreme: allow all implementations to choose what is their threat vector / what mechanism makes the most sense for them to get user consent. Alternately, dictate a standard. Another thing that was put in directly as a mitigation: bifurcation into buckets. Personal feeling: DateTime bucket contains preferences that are not as sensitive, more difficult to fingerprint a user from them, and also having it significantly improves UX. Having the ability to operate differently for either bucket / give user consent for one bucket but not the only, purely because the (for example) the measurementSystem I have in place makes it much easier to fingerprint me than the hourCycle.

YSZ: I have one question. I think that we do not want to increase the fingerprinting vector. If the user would like to offer the data, we should ask for consent. It works for the JS API. But these Client Hints are the request header. Do you have a story about how to get consent on sending this in header when accessing the web site?

RCA: It's the same as user agent client hints. The mechanism is the same, or very similar.

YSZ: If you open a website, do we send this information? 

RCA: Aside from in Client-Hints, the headers, yes they do.

YSZ: When do we get consent? 

RCA: There are low-entropy and high-entropy client hints. I'm not sure about the flow at the level of the UI. But I can confirm that and come back to you.

YSZ: We can get explicit consent from users. For the header to request some access from the network, we need to get consent – but we don’t have time to get consent to affect HTML

RCA: What are the opinions for Client-Hints in your case

YSZ: If it increases fingerprinting, we will not use it.;

RCA: Are buckets as exposed here are a better option?

YSZ: I'm thinking that the buckets will work to avoid getting a lot of permissions from the users. It gives coarse-grained permissions. But we're not thinking that we should expose this information without any consent. If the proposal adds a fingerprinting vector without consent, that won't work for us.

HJS: I think it’s a bit problematic to build this feature on the assumption that the get high-entropy features value API. In Chrome, a “privacy budget” which getting high-entropy values exhausts, it’s not explicit consent but if you ask for too many of these, they get blocked. In terms of user experience, this is different from explicit consent. And then, if the assumption is that there is user consent, the question is what kinds of sites are the ones that drive the demand for the feature? On Google Calendar, for example, the calendar app itself has settings like first-day-of-week within itself. And the user is typically logged-in. So would the vision be that Google Calendar would invoke a constant API at some point in the user account lifecycle to import the settings? That's quite significant for whether it's okay to prompt.

RCA: There are two parts of this answer. Use cases as shared on previous presentation – use cases that are already applied when you use native applications. The mechanism itself and user workflow / experience, I’m not sure if we’re in a real place to discuss that, but understand your concern and the importance of protecting this data in a way such that the user knows precisely what is going on. 

SFC: Two things: The question Romulo originally proposed: are these good buckets? Does the way that we’ve split them make sense. For example: first day of week and calendar, which bucket should they be in. Second comment: it seems like the overall sentiment of this group is that we want to think about the end user experience rather than the mechanism. We’re unclear on what this means for the end result: does this come out of a privacy budget, is it a consent bubble? Need more clarity – that might be a good next step. To answer HJS question re: what is the use case, the goal here is to improve the multilingual web. These are settings that native apps can already access, but that web apps do not necessarily have / can’t use to customize experience. They can only guess based on the Accept-Language header, results in lower-quality experience for users on web platform. Goal is to be fairly broad, in the sense that websites can automatically use (for example) the correct hour cycle if user has hour cycle preferences that differ. 

RCA: How do you feel about these preferences? Do you feel comfortable with these two buckets, should we have more?

SFC: Let’s take this discussion offline. 

USA: Regarding the delivery / use of Client-Hints, that decision was taken collaboratively within this group because of concerns raised. Listening to points made by YSZ, if implementers would think it’s safer to have a getter on the navigator object (as in geolocation) that’s a path to go down. Final goal is to give this information that already exists in all modern operating systems to a web developer to actually use the Intl APIs without exposing that to fingerprinters/bad actors. We could certainly redesign this to better fit privacy concerns. 

HJS: At the risk of bringing another point about what's common and what's not, from bug reports I've seen, it seems that a driving use case for overriding this stuff comes from US English being the untranslated language for much of the software business, so if you run nightly builds with the strings that software developers check-in to the repo, en-US is the untranslated thing. This is acceptable language-wise, but it's not acceptable for formatting conventions. The US region is unusual for pretty much all of these preferences being discussed here. Metric units, Celsius, Hour Cycle, etc. That raises a question of, is it known the extent to which people change these settings with all base locales, and the extent to which the desire is driven by changing settings away from the US region? If there was just 1 bit of entropy, like let's flip all of the settings to the international settings, how far would that go?

USA: That is something that comes up a lot. However, it doesn’t quite encapsulate a majority of the users we’re thinking about here. Example: the defaults en-US locale can be rather odd, but at the same time it is something that a lot of people in the US are quite comfortable with, that they use for minimal changes. However, en-IN is an awkward mix of everything: spellings, first day of week, and so forth are different than you’d expect, and the numbering system, etc. The idea is how many people have to work around their locale in order to get an i18n experience that they feel works for them. For instance, many people using en-IN would change the numbering system. Does the extant system allow us to express things in this way?

SFC: I have an answer, but it’s longer, can bring this discussion offline. 

RCA: We will consider the buckets & experience points mentioned here.

SFC: We should bring this up for discussion every month so that we can continue to iterate on it. Good goal by next month is assembling well-documented answers to HJS and YSZ’s questions.

### Temporal issues: #2479 prevent loss of TimeZone information 

https://github.com/tc39/proposal-temporal/pull/2479

PFC: Temporal has a type, ZoneDateTime, that’s an exact time that carries a time zone along with it, it provides time-zone-aware conversion of exact times into wall-clock time, what the intention of this type was that when you format it you get the information presented in the time zone that belongs to the type. For example, what happens if you call toString() on an instance of that type. 

If I have the exact time (0 seconds since the epoch) and I have the timezone of (say) New York, what I’ll get is Dec. 31st, 1969 at 5 hours before midnight. What we discovered that because of an oversight in the spec text is that it would always ignore the time zone that the object carries with it. In the example given before, you might get 7:00 PM Dec. 31st from toString(), but you’d get whatever it was in the user’s local time zone because that is what would be created when you create a DateTimeFormat without a time zone argument.  Focusing discussion on three questions via Justin:

I've found it helpful to think about this PR as addressing three related but not identical questions:

Should optionless ZonedDateTime.p.toLocaleString() use the ZDT's time zone or the system time zone?
Should optionless new Intl.DateTimeFormat().format(zdt) use the ZDT's time zone or the system time zone?
How should conflicts be handled (in either API) when a timeZone option is provided and it conflicts with the ZDT's timeZone property?



FYT: PFC brought this up for TG1 consensus last week but I felt it should be discussed here in TG2 first. I encourage other implementors to take a look. But in its current state, I would like to block, for the following reasons. From my point of view, this touches two things: toLocaleString, and DateTimeFormat. It's necessary to be coherent with the DateTimeFormat object you've already created. In other cases, those two things are equivalent in other usage. DateTimeFormat is intended as a way to cache the results. It serves a slightly different objective, which is a performance improvement. But for DateTimeFormat, it exists; it's not a new thing. It was previously used only for formatting a Date. What that means is that Intl.DateTimeFormat has a way that first, the user can pass in a time zone, and second, if the time zone is not passed in, it will resolve to the default time zone at construction time. So the issue comes that whenever the resolved time zone… it's new that ZDT brings its own time zone. It's a problem only when the two values are different. If the ZDT time zone is the same as the system default time zone, it's not a problem at all. We need to have a solution not violating either of them. My reading of the PR is that you construct a Intl.DTF with a specific time zone. In this particular PR, if you pass in a ZDT with a different time zone, then you get a different result. It's incoherent/inconsistent. The same DTF will result in different time zones, which violates a previous DTF design constraint. I do think we need to have a way to address the ZDT toLocaleString. One possibility is that whenever you call it, instead of internally constructing DTF with no options, you can just pass the time zone to it, and then, in the Intl.DTF format function, if you get a ZDT come in, you can choose to either format it or throw an error if the zones are inconsistent. And that will comply with the previous design of Intl.DTF. But I think the current PR violates that design.

JGT: Could we constrain the discussion to question 1 from the list above? Does anyone object to using the ZDT if used w/o options

USA: I think clearly ZDT.p.toLocaleString should use ZDT's time zone. I think optionless Intl.DTF should use the ZDT's time zone.

SFC: I think this issue is closely related to issue #750 – what do you do with the time zone change events? ZDT has long had the invariant that the timezone used to construct is used for formatting. There is cost to doing a time zone lookup – it’s not free. One reason we have a constructor is so that we can frontload that lookup cost. It still has to do lookup cost for month name or era name, but doesn’t have to do lookup cost for time zone name. To answer the questions on the board: Clearly option #1 should use time zone. Question #2 is the one where we have to think carefully about what happens here. One proposal that I posted on issue #750 is that we could start by having a strict behavior and having it more lenient over time. Most strict behavior: if you want to format, use toLocaleString. Another option, a little less severe: allow the ZDT but the time zones have to match. Certainly we could say that ZDT is special and we’re going to change how Intl.DateTimeFormat works – follow ZDT? If we think it’s useful for users, we should do it, but it does require work on the implementation side. 

PFC: There are concerns, we’re trying to get to the bottom and find a solution that everyone can agree on, not blocking in TG1. Note that toLocaleString is always equivalent to creating a DateTimeFormat with the options that you pass to toLocaleString call. If we strictly wanted to keep that the case for ZDT we’d have to require that you pass the timezone option in the toLocaleString call – would probably be least useful for users. If we consider question 1 non-controversial, we may have inconsistencies.

FYT: What inconsistencies? 

PCO: What I mean by inconsistencies: An invariant of DateTimeFormat and Date.p.toLocaleString, up until now, is that if you call Date.p.toLocaleString with a locale and options format, it constructs a DTF with that same local and options format. If we want to modify toLocaleString w/ ZDT providing its ZDT, that introduces an inconsistency where the options object you pass to toLocaleString doesn’t match the options passed to DTF 

FYT: I want to clarify, this is not true. Date.p.toLocaleString is not passing the exact options bag into the constructor, so it was consistent. It’s a special case because there’s multiple variants to the toLocaleString and the options bag is always processed before passing in the values.

JGT: Do we have consensus on question #1

FYT: +1 from me

JGT: A plain month/day will ignore all the other options, etc., because there’s no time zone in plain month/day. [other similar examples] We should have a reason/justification for why the time zone is different than all these other options. 

SFC: Great question, the line is clear in my mind. All these adjustments can be precomputed. When I use a PlainMonthDay, I can precompute it in the constructor but with ZonedDateTime, we need to do it in the format function. This is the problem here, that we need to resolve it in the format function instead.

JGT: To clarify, your point here is that this is an implementation issue rather than a consistency issue. FYT objection based on consistency, SFC objection is that it will make things slower/bigger 

FYT: I do have implementation concern, but first level concern is consistency. I do think SFC’s right that the timing of the decision is different. Also, time zone has no conflict – don’t have another object conflicting with you. 

RGN: All options make sense from different perspectives, so long as there’s consensus I’ll be satisfied. 

SFC: There nobody on the queue. I did list some concrete options in one of my posts somewhere, but there are multiple threads. The high level question is: what should the format function do with respect to ZDT.

1. Don't accept ZDT in DTF.p.format
2. Accept ZDT; throw if the ZDT's time zone does not match the DTF's time zone (including the implicit system time zone)
3. Accept ZDT; if the DTF was constructed with an undefined time zone, use the ZDT's time zone; otherwise, if the DTF's explicit time zone differs from the ZDT's time zone, throw; otherwise, the time zone matches, and use it
4. Accept ZDT; use the ZDT's time zone, ignoring the DTF's time zone
5. Accept ZDT; use the DTF's time zone, ignoring the ZDT time zone
6. Add some option to the DTF constructor that tweaks this behavior
7. Add Intl.ZonedDateTimeFormat

FYT: I think there’s one additional parameter to take a look into: what would happen if you have a ZDT, call toLocaleString, and we have an option bag which itself has different a time zone – a third time zone now. What should we do? 

JGT: Explain the three cases you’re talking about – I only see two.

FYT: Internally I agree with you, but you have to look at three things. Say you’ve got a ZDT that says Italy, your toLocaleString passing an option bag, option bag says Beijing, which tz format for toLocaleString.

JGT: That’s my question 3: how do we handle conflicts?

FYT: There are two different options – Intl.DateTimeFormat and toLocaleString, have to distinguish these two. In the code itself it’s probably glued together in one way to resolve it, but from the calling point of view it’s in two places .

SFC: Generally strongly in favor of making them work the same. In this case it’s probably warranted to do special handling of the time zone format. I think we can isolate that in the toLocaleString function. This question should be answered separate from the more general case. On the toLocaleString, what the behavior should be, there are a few options. 

1. Do not read the timeZone option in ZDT.p.tLS (use the ZDT's time zone)
2. Error if timeZone option is in conflict with ZDT's time zone
3. Error if the timeZone option is provided, even if it is the same as the ZDT time zone
4. Obey the timeZone option even if it is different than the ZDT's time zone

JGT: My opinion is that #2 is the right behavior, we already have an API for changing the tz of a ZDT, doesn’t seem to be particularly valuable to have another way – if you want to change the timezone, use the Temporal API.

JGT: My vote’s for #2 

USA: I see the point, but unless the time zone is provided explicitly erroring is not great – feels a bit unexpected. When it is provided, I am happy with either way (if it errors or if it doesnt)

JGT: we’re only talking about the case where options are provided, correct? Let’s defer the question of when there’s no timeZone option.

SFC: Option 3. I was thinking option 1 would be best, but we should be strict. Don’t pass a time zone into toLocaleString function – error even if it matches so long as it’s not undefined (which just means inherit from ZDT) 

JGT: What do we do with timeStyle?

SFC:

```javascript
new Intl.DateTimeFormat(undefined, { dateStyle: "long", year: "numeric" })
// TypeError: Can't set option year when dateStyle is used
```

FYT: I support option 3

JGT: Fine with #3

PFC: I think this part could be designed offline – doesn’t really have to do with the concern about the PR. I’m fine with option #3, though.

SFC:  We resolved this little mini-question. Let’s go back to the big question. If someone creates a DTF from the constructor and passes in a ZDT, what do we do? 1: never accept it, 2: only accept it if they match, 3: use timezone from ZDT but only if constructor had an undefined time zone, 4: always use ZDT’s time zone and ignore DTF time zone. Options 3 and 4 require us to change the format function. 

FYT: Option 3, when you say use its time zone, which are you talking about?

SFC: ZDT

JGT: The question about when the system time zone changes is in these cases when it says “including the implicit system time zone”, that does not track changes to the system?

SFC: that’s 750, we don’t need to decide that right now.

FYT: Are we talking about only the format function? 

SFC: The format function of DTF. Not talking about toLocaleString

FYT: In that case, implicit time zone change has no impact, the only thing that changes is the DTF constructed after that, we can remove that part of implicit system timezone change. 

JGT: Probably another option: add an option to the DTF constructor, an auto option for time zone. Not saying we should do that, just saying it’s another option. SFC, to answer questions about what I’d prefer: I don’t like #1, because we should be able to format these things, #2 is fine because it matches the behavior we were talking about from toLocaleString, #3 also okay, and I do not like 1, 4, 5, and I haven’t given 6 enough thought.

SFC: My opinion: [ ] consider option 3, not happy with option 2 because it’s a footgun: I don’t like throwing exceptions in cases where you just didn’t test it, option 2 seems like a case where that would happen. If we’re not going to be re-architecting anything, safest to start with option 1. Option 7: add Intl.ZonedDateTimeFormatter, add new class w/ this custom behavior. If we did option 1, we can move to another later. Option 5 might be surprising – ZDT should be, conceptually, the one that wins.

PFC: Preference; I don’t like 1, 5, 6, or 7. The PR that’s up for discussion, the current state of it, does something similar to 3, but not quite. 

FYT: That’s 4, right?

PFC: Yes, you’re right. 

FYT: I object to 3 and 4. Both impacts design and also implementation. 3 impacts performance, impact all things about date benchmark for toLocaleString(), big impact on memory usage.

PFC: We need to take this into account, but this isn’t the ultimate goal of an API

FYT: Impacts user – user will find toLocaleString slower.

SFC: That’s convincing for option 3

JGT: Why does this impact performance? Because Date.toLocaleString is internal, the format it uses is not the publicly accessible one, you would not necessarily have to change the slots of DTF to support Date.toLocaleString. My understanding is that when you call Date.toLocaleString are you producing an observable DTF that can be monkeypatched? Nothing here should affect Date.toLocaleString, because there’s not ZDT and no observable DTF call.

FYT: In order to do 2, you have to make a spec change. In order to do #3, your spec test has to change the way the date goes through that part. There’s no mechanism to remember that, you have to change the slots.

JGT: Intl.DateTimeFormat.Format could get slower

FYT: The toLocaleString of the date _is_ calling that one. 

SFC: Note that #4 is best from user perspetive

FYT: how can it be good for the user to have two different time zones? Totally against use case. 

SFC: Most of the time the DTF is constructed with undefined tz. If you construct it with an explicit timezone the ZDT also has an explicit timezone, and that one is more explicit.

FYT: No!

SFC: If you don’t care about the time zone, you should use Temporal.Instant or just plain DateTime. Only time you use ZDT is if you care about the time zone

JGT: I think my preference now is for 3, because if you specify an explicit time zone that’s part of the options, and ZDT has a different time zone, for the same reason we decided to not allow that in toLocaleString, that holds true here – it’s unclear which should win. If it’s undefined in DTF, support pulling it from ZDT

USA: The rationale that you gave does make sense, but for the sake of consensus I concur that 3 sounds like a good way forward, consistent with the way we deal with things. Also something we can get consensus on – realistically, why not? 

SFC: I’ve heard concrete concerns about all options – my understanding is that the concern with option 1 is that we should be able to format these, weird that we cant in DTF, concern with 2 is that it’s unlikely to be caught before deployed, option 3, changes data model of DTF, increases memory usage, impacts formatting of other types of objects, option 4, it doesn’t retain the memory of the DTF timeZone which is an explicit option, concern with 5 same but the other way around, concern with 6 and 7 we haven’t discussed. I don’t see any of these as near consensus 

PFC: When evaluating these competing priorities, I like to use the w3c priority of constituencies argument. For me the concern with 3 (change of data model) weighs less than concerns with 2 (people might get exceptions in production that go unfound in testing). Different levels of concern, framework like priority of consistencies helpful here.

FYT: I don’t understand #2’s issue, could pass it in in the test to fix it and it will always throw. This is a shortcoming of bad unit tests, you cannot prevent bad engineering to do that.

SFC: If you have a call site that uses an undefined timezone (local timezone) but ZDT is created from Temporal.Now, you’re not going to get exceptions, in testing you might not to think to test it with a non-local timezone on it, seems like an easy mistake to make – it’s bad testing, but an easy mistake to make.

FYT: In that case both DTF and now would return the same result, would not throw error.

PFC: If you get ZDT from a string (from a database, etc.) it might differ

JGT: SFC, your argument is pretty compelling. The vast majority of DTF generated will have no timeZone option, we should optimize for that case, if people start using ZDT and pass into an existing DTF (create without parameters, which most are) it could cause problems. 

FYT: The argument of “majority don’t pass time zone” is unreasonable. Discussion of how many of them don’t have a time zone shouldn’t be considered – 100% of them are not passing Temporal. 

SFC: One thing we’ve achieved is that we more clearly understand everyone’s concerns – maybe we can follow up on PR and find something we can agree on. 

JGT: Maybe remove the ones no one likes? 

SFC: Will include the list in the post I make.
