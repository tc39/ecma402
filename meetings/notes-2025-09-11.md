# 2024-09-11 ECMA-402 Meeting

## Logistics

### Attendees

- Shane Carr - Google i18n (SFC)
- Ben Allen - Igalia (BAN)
- Eemeli Aro - Mozilla (EAO)
- Jesse Alama - Igalia (JMN)
- Philip Chimento - Igalia (PFC)
- Frank Yung-Fong Tang - Google i18n, V8 (FYT)
- Yusuke Suzuki - Apple (YSZ)
- Richard Gibson - OpenJS Foundation (RGN)
- Daniel Minor - Mozilla (DLM)

### Standing items

- [Discussion Board](https://github.com/tc39/ecma402/projects/2)
- [Status Wiki](https://github.com/tc39/ecma402/wiki/Proposal-and-PR-Progress-Tracking) -- please update!
- [Abbreviations](https://github.com/tc39/notes/blob/master/delegates.txt)
- [MDN Tracking](https://github.com/tc39/ecma402-mdn)
- [Meeting Calendar](https://calendar.google.com/calendar/embed?src=unicode.org_nubvqveeeol570uuu7kri513vc%40group.calendar.google.com)
- [Matrix](https://matrix.to/#/#tc39-ecma402:matrix.org)

## Status Updates

### Updates from the Editors

BAN: Merged editorial PRs #1024 and #1025. The normative PR #1026 will be discussed later this meeting.

### Updates from the MessageFormat Working Group

EAO: The version of the spec proposed by the working group to CLDR TC for inclusion for CLDR 48 has been approved as of yesterday, so that’s good. Otherwise we’ve been mostly on break, I think the only notable development is starting to look into establishing a dictionary or language to use for attributes to attach to parts of a message and to messages themselves.These attributes have no impact on formatting, but are useful for communicating between implementers, translators, and other users. 

EAO: If there are thoughts on what the working group should work toward for next spring, that would be useful, to account for them with our priortization going forward. 

### Updates from Implementers

https://github.com/tc39/ecma402/wiki/Proposal-and-PR-Progress-Tracking

YSK: No updates

FYT: Me either

SFC: Need to update MDN for recent PRs / verify that they don’t need MDN. Need help from SM developers to make sure that the spreadsheet is reflecting the state of the world. 

YSZ: We could probably check the status based on our corresponding tests.

SFC: It appears that everyone is implementing DurationFormat and that we don’t need to track it as a PR. The other three we should track for.

PFC: note in a test262 PR, a green job does not mean the tests passed in that engine, it just means they executed. you have to go into the job log and look at whether they passed

### Updates from the W3C i18n Group

SFC: Now we have the new process to request reviews that we decided upon last month. Not sure we have additional updates

EAO: I have not yet requested a review for trailing zeros, but intend to do so once I figure out how – have not spent much bandwidth on thinking about this

SFC: File a github issue using their template. W3C i18n group meets 7:00 AM/PST, should be attended by someone in east coast or Europe timezone. Once a month for a liaison is sufficient.

EAO: I’ll try to join the call over the next week or three, but I cannot do so on a regular basis due to internal Mozilla meetings that conflict with that.

SFC: Having someone join once a month is better than what we currently have.

## Proposals and Discussion Topics

https://github.com/tc39/ecma402/projects/2

### Standard Measures with U.S. English

https://github.com/mozilla/explainers/blob/main/standard-measures-en-us.md

SFC: HSI, could you give an overview of this explainer?

HSI: The context for this explainer is a couple of previous rounds of proposals in this group around overriding various aspects of things that are implied by the locale, and the main problem with those is that if you give granular overrides for things those are a privacy problems, because a combination of the overrides is likely to become unique.

HSI: The general problem that this is trying to solve is that users who don’t have a connection to U.S. date time formatting and measurements are using en-US. The United States is maximally unusual. In every instance where the whole world doesn’t use the same system, the United States is the exceptional region, aside from blood glucose, which has very many exceptions. Many people running the US UI are unhappy with the U.S. measurement conventions. This addresses this through a language tag that has the semantics of U.S. English + standard measurements, currently en-ZZ, because it’s assumed that en- and two ASCII letters is more likely to be webcompat than en hyphen and something more complicated. If this were to work out, the number of patches to CLDR to enable this would be pretty small. There is a list of those.

HSI: There are two main risks in this. The first is that we have not carried out an experiment in making a browser advertise en-ZZ and seeing what happens. We don’t know the way the web reacts to a browser claiming this locale. Another significant issue is that using international standards for the things that trigger on region, one of those is first day of week, and ISO weeks are the international standard, and ISO weeks start on Monday. However, having weeks start on Sunday is a broader thing than just the U.S. This is not the case where the U.S. has Sunday and the rest of the world has Monday, and there are many places that have Sunday

https://en.wikipedia.org/wiki/Week#/media/File:First_Day_of_Week_World_Map.svg

HSI: If you are in a locale that uses Celsius and you see Fahrenheit, you may not be happy about it, but you’re not going to mistake it for a temperature in Fahrenheit. Same thing, you’re not going to accidentally think that something in feet is in metric. Anecdotally, if you see a 12 hour clock, even if this isn’t your preference, you can by reading the analog clock see what it means. Start of week is different, since if you see a calendar with the first day not what you expect, it’s easy to read it wrong, and those mistakes can be messy and expensive. Anecdotally for me as a European, the most problematic thing for me as a user is first day of week. From my perspective that’s the top issue. But what about the users from non-U.S. locales with weeks that start on Sunday. If we automatically give them week starts on monday for date pickers, we add this problem that they don’t already have, which anecdotally for me is the worst problem. That’s the biggest thing that looks like “what do we do about that?” in this proposal. Those are the main identified problems: not having tested it in the wild, and the first day of week thing. Making an exception for first day of week erodes the idea of there being a single identifier that’s “U.S. English with standard measurements.” I’d be interested in hearing what folks who’ve read the proposal think about this.

EAO: Not going to comment much, since I’ve been working on this with HSI separately, but noting that we are proposing more than one thing here. First is that we think something like en-ZZ should exist, and beyond that that it should be the default in certain situations. If we cannot always use it as a default outside the U.S., that doesn’t mean we can’t define en-ZZ and get utility out of it. We need, though, to figure out what parameters we’re working with this in. We would also like to hear if there are other dimensions other than start of week that are potentially problematic, so that they can be addressed in this. 

SFC: Thank you, HSI, for taking the time to write this up. I have several comments. I’ll start with one: I think that this proposal, this en-ZZ proposal, it solves a specific need. It describes the needs of users around the world who prefer an en-US locale for various reasons, but prefer to have metric and other world conventions for measurements. That is a need to solve – I’ve seen this come up a lot with clients I’ve worked with across google, who say it’s a real need. What I would like to see is in general, I feel like this is sort of taking a general problem and solving a specific aspect of a general problem. The general problem continues to be that users prefer one region but regional defaults from a different region. I would rather see a solution that can generalize, regardless of whether or not we want to generalize it. en-ZZ seems quite narrow. I have more comments, but I’ll start with that one.

HSI: There is a mention in the explainer itself of why US English is special enough that it makes sense to address it specifically. It’s not the case that people need ot match things in general, but it is the case that en-US, because it is the language that major software is developed as and translated from, that it gets used out of locale on a magnitude that’s different from anything else. Last time, when we previously talked about where do the generalizations come from, it turned out that the motivation behind them was about the case where U.S. English is used out of locale, and then the generalized examples were all working backwards from the idea of needing this kind of override, and then coming up with something else. My recollection is that when we looked behind, I think the examples were Hindi with Devanagari digits rather than Hindi with Latin digits, and I think it was the Thai Buddhist calendar in Singaporean English, but those were not the motivating cases behind it. What was behind it was U.S. English in India, and that was what had kicked off this discussion. I think the U.S. English case, U.S. English being used outside the U.S. is so big and so special that it makes sense to address it specifically, and trying to generalize can be a distraction.

EAO: What HSI just said, and also noting that in a narrow dimension this can be thought of as being a generalizable thing, in that if we do pick something like en-ZZ with ZZ as the region that triggers the behaviour, it’s plausible that someone else can show that another language than English has a similar situation, which could use the same region code to trigger the same behaviour. This isn’t what you’re asking for, but it is a little bit of a generalization of what we have.

SFC: The cases that we have, like digit systems in Arabic and calendar systems in Singapore, among others, largely occurring in the global south, are real use cases. When building a multi-lingual Web we don’t want to be English-centric. In terms of numbers U.S. English is the largest case of this situation, probably by a fairly large number. But if you take all the other instances that are smaller and add them up, I wouldn’t be surprised if the sum of users impacted by this problem not covered by en-ZZ are similar to those that are covered by en-ZZ. We are leaving a lot of material on the table with this in making a solution that’s not general, it doesn’t really make any progress of solving the issue of making the Web more accessible to users in general that live in regions that don’t reflect their needs and preferences. It does make progress, which is good, but not a way that solves the other issues.

EAO: Although this doesn’t solve the scope of the issue that we could be solving here, it doesn’t prevent further solutions from being implemented later. It doesn’t block any other solution from being adopted later. I’m concerned that the argument is that you’re making is looking for perfect, and we’re looking for good, and good should be good enough for a next step for us to take.

RGN: I really appreciate this explainer, I think that it’s well-founded. I think the specific proposal to use a region for indicating unknown region/global english makes sense and does generalize. My most significant commentary is that I think this working group is not necessarily the right venue to handle it, and it should be in CLDR

EAO: I agree… one reason we want to discuss it here before bringing it to CLDR is to go to the CLDR-TC and say that we are an interested user of this locale, so the question we will be asking is one where it is not an academic interest, but one that we desire to implement and use. 

RGN: To that extent I’m in favor.

SFC: One last comment on generalization, en-ZZ generalizes in the sense of a locale that lets you use global preferences, but doesn’t generalize to cases like Singaporean user wanting to use Thai Buddhist calendar, or digit systems in Arabic, where people want to use something other than global standards. But I acknowledge your point about good vs perfect.

SFC: About this exact mechanism, I was reading in the explainer HSI lists out some other possible approaches, and one I wanted to discuss was about using the region override subtag, since I think it’s a mechanism we already have that largely does this. If we were to just use

`en-US-u-rg-001zzzz`

I think that – I don’t know if that’s correct syntax, but that does accomplish that. I can check with CLDR to see if this is the right syntax. I’m concerned about using ZZ itself, since it indicates the absence of a region, and is used that way in for example the likely subtags algorithm. en-ZZ and en are the same locale in many Unicode algorithms. That’s one concern I have with this specific concrete solution. Since Unicode does have other mechanisms, it’s not clear why we would shy away from those existing mechanisms. HSI, you addressed the region override topic in your explainer.

HSI: There are two issues. First is that anecdotally a two-letter subtag is likely to be more webcompat to something more complex. We have, though, not carried out the experiment in exposing en-ZZ to the web. Running the experiment with en-US-u-rg-001zzzz as the region could be useful, to see, like, what if we exposed that, what if we exposed en-ZZ, how do websites react to that. The other concern doesn’t apply to 001, which is that if you put something like Finland or the Netherlands in the override, that needlessly overrides the anonymization. That doesn’t apply to 001. Do you have a link to the likely subtags algorithm?

SFC: It’s in TR-35. I’m referring to the section that says “the only subtags that can be replaced are deprecated ones, und, ZZ, ZZZZ.

https://unicode.org/reports/tr35/tr35.html#Likely_Subtags

HSI: that is likely something that I wasn’t aware of and didn’t take into account while writing the explainer. This is important information.

RGN: The text that SFC just highlighted had error signalling being allowed to use ZZ and algorithms being allowed to remove it, but if they don’t remove it it’s still available for further input, and if they’re using it to signal an error, falling back to global conventions might be a good result.

SFC: I wanted to raise it as an issue to be looked at later.

RGN: On the previous topic, using the region override, the current syntax for that is a region subtag suffixed by either a subdivision or ZZZZ. I want to know if you’re proposing we might use that as-is, or instead modify it to no longer require the suffix. You asked 001, it’s not currently a valid value for u-rg.  Whether or not you’d be proposing a change that this is valid –

SFC: I want to use whatever the existing syntax is for a three-numeric-character region.

RGN: It is the same as for letter regions

EAO: I have two concerns regarding using something like en-u-rg-001 as the way to trigger the behavior we’re looking for. I’m not opposed, but I have two concerns: 1) it’s weird and long, and effectively an incantation that’s difficult for human people to remember if they need to interact with this, and they will get it wrong. There will be cases where developers are interested in explicitly opting into this behavior. If that works, this sends a strong signal that all the other region codes also work, and specifically in the context of browsers they do not – they end up being stripped away. Ending up with something hopefully a two letter code would be much more memorable for users to know what this thing is and to be less likely to raise questions and concerns about “why does this work but this other thing not work?”

SFC: This brings me to my third point about this, which is that it’s not clear to me what exactly the impact is on ECMA-402. In ECMA-402, if a browser were to add en-ZZ, 402 already supports that. Firefox tomorrow could ship en-ZZ as an option for languages to accept. The explainer goes a little bit into detail on heuristics that engines can use to choose whether or not a user should use en-ZZ. Browsers can already do that.

HSI: The issue of what is needed – if the use case is that you’re invoking the ECMA-402 API without specifying a locale, you get the user’s default locale, and we’ve used heuristics to determine that we should use en-ZZ, and the browser has made the patches to CLDR that the explainer mentions, then that would work for the case where a web site is using intl API without specifying a locale or using intl API by plugging in the first item of `navigator.languages`. It would, though, not account for the case where the site is taking the first item from `Accept-Language` and plugging that into a server-side mechanism that has an unpatched CLDR backing it. Making this more formalized upstream than a browser patching CLDR under whatever spec language 402 has, means that the semantics of this thing would extend to cases where the site is doing processing other than by using the browser-provided CLDR. 

SFC: But we don’t reference CLDR in 402

HSI: But we know that the browsers implement 402 on top of CLDR – pretending that that’s not the case is not that useful as a practical way of reasoning about what would be the effect of this or that.

SFC: I wanted to talk about how this relates to my previous comment about using u-rg. If `Accept-Language` were to be en-US with en-001 (?), that already works in CLDR and ICU, they already have that as a definition. My reading of ECMA-402 is that engines are allowed to do that but none of them do. If we were to have language that language can do this, we then basically – an engine can add one item to the list of allowed locales, you could pick en-MX, fi-FI, or you can pick en-US with a 001. That’s one of the locales that users can pick that is allowable with ECMA-402, but the subtag isn’t something that users see – it’s very much an internal concept. It seems harmless to me to make that be the locale that’s used for this case. What’s the downside?

EAO: The way I would put it is that we are kind of here talking about en-ZZ because it’s the first place we ought to discuss it, so that we can establish that this is the best forum for us as browser makers to talk about i18n methods, if we can identify if this or something like this is something that we want to exist, as we have needs re: how browsers works, privacy concerns, [?]. Furthermore, en-001 is close, but it doesn’t match standard measures of en-US localization with standard measures, which is the best solution that we’re looking for here. We are looking to ascertain that we are an interested client for a CLDR/ICU implementation for this locale. I also intend to raise this issue at the W3C i18n working group, so that we can advance things for the users of JS ECMA-402 specifically, even if no specific spec text in 402 or 262 is likely to change. It’s a concern we have as people developing and maintaining these implementations.

HSI: What’s the harm of using en-US-u-rg-001ZZZ. en-ZZ hasn’t been tested. At any case proceeding would need actually testing what happens if you make the change in the browser and browse the Web, how does the Web react? The experiment hasn’t been run. But everything that experience as a browser development tells me about how the web behaves, it’s reasonable to assume that en-XX with XX as ascii letters is more likely to be compatible. That is based on experience, but the actual experiment hasn’t been run. But as a technical detail, if we did u-rg-001ZZZZ, one thing to look at is do the ICU and CLDR semantics allow for providing a date/time formatting pattern that differ from en-US. One of the items identified here is giving the gregorian patterns, the ISO patterns. Is that something that the infrastructure allows for that language tag? 

SFC: One more comment about this generally. I noticed that one of the cases you had brought up in the explainer that I hadn’t considered before is this idea that – here it is in appendix 2. Everything in Datetime formats, everything is covered except for this, it’s not covered by u-rg. There has definitely been some discussion in CLDR design working group about allowing users to select a datetime format that differs from the locale ordering, usually by adopting the ISO ordering. I wanted to note that this is an active discussion in the CLDR WG, there have been many approaches, for example using u-ca subtag. That proposal got close to landing but then was reverted because it broke stuff. Another proposal is adding a new calendar subtag. A third proposal is just having a new locale subtag, something like u-ca-dt-iso (?). We’re going to be a client of this and we’d like to explore this area. If we did add a unicode locale extension for this, it fits nicely with the existing Unicode framework of using the rg subtag.

SFC: Re: web compatibility of 001, there’s a few ways we could mechanically do this. One would be to put it in `Accept-Language` as a fallback language: you could have `Accept-Language:` be `en-US, en-US-u-rg-001`. We say that if the locales the same but for the extension keywords, then we use the extension keywords in ICU. When we do the test we may find that a lot of things would just work, en-US is already matches the resource bundles. en-US with the locale extension subtag still matches the en-US bundles. There are a few mechanisms to be explored. One reason is I like the Unicode extension keyword approach, if we can get that to work that’s the more desirable outcome.

HSI: To clarify about the date format, it’s important that it’s not just about ISO order, it’s about ISO hyphen separator. It is the case that there are some locales that use - as a separator for something other than dates, there still is a strong indication that if you come from – if en-US uses slashes, in the English context if you have hyphens, and especially if the year comes first, you know that “if the year comes first you have hyphens, so it’s big endian all the way”, it’s not just the order that’s important, it’s important to use the non-slash hyphen separators when the ordering changes. As a general lament, it’s a bit unfortunate that there isn’t a separator that would universally be big endian. Hyphen is best for this, dot seems to be globally little endian, slashes is all over the place – the endianness of slashes is most ambiguous. It’s important that it doesn’t only permute the order but keeps the slashes, that would make the problem worse. 

FYT: For high-level it’s good, we should look at more subcases.

YSZ: I agree with FYT

SFC: What do you see as the concrete next steps HSI?

HSI: The concrete things: first, running the experiment of what happens if a browser exposes en-ZZ, or en-US-u-rg-001zzzz? If either of them has backwards compat issues, nothing else matters. The second thing would be, if we were to do this region override instead of this region code, how would the date pattern override work into the LDML/ICU mechanism? Is that harder than making a CLDR patch for en-ZZ. Then there is something, a small thing that makes sense regardless of the rest would be to change 001 minDays from 1 to 4 (to use ISO week numbering).

HSI: In parallel, what should the heuristic be where there’s a three-way setting, do you if you use en-US do you do automatic promotion to U.S. english with standard measures, or do you have a user setting where the user says “no don’t do that” or “yes please do this.” What’s the right heuristic for the automatic mode, that’s a site for research. If the browser queries the system settings and all line up with standard measures, that makes sense. But if the system settings are a mix of things, what subset is a suitable signal for deciding.

BAN: One of the things I like about this is telemetry data. I wonder if something to investigate is the use of numbering systems in Afghanistan, since there’s parts of the region with a split between Latin Arabic numerals and Eastern Arabic numerals. One problem is that it’s safer to split up users of en without individuating them, since it’s such a large bucket.

SFC: It’s harder to get telemetry data outside en, since these settings are not easy for users to set. Some operation systems but not all let you change those numbering system settings. It’s harder to get that data – I think the way to do it is to do actual research – surveys and so forth to give that actual data. I don’t know if that telemetry thing generalizes in a way I’d like it to generalize. On that point, I would still like to see a solution here – HSI has stated with a bit of a handwave that en-US is a problem, here’s some telemetry data, why is that a big enough problem? A number of users impacted, a percentage of users impacted, just sort of a feeling? I like having telemetry data, but 

HSI: The case where a user used en-US but complains/files bugs… that's a thing that actually happens. This has happened in India, and with Mozilla and European users. So it comes through a bug database. For the other cases, if someone looks at how do we solve that, thinks about how do you generalize, and what other thing could use a generalization, those other things aren’t things that come through a bug database. That’s one signal that the en-US situation is a special thing and the telemetry – how much UI languages are used out of locale when comparing with telemetry submitters geoip, unfortunately I only got these numbers that are in this document cleared for release, so I will have to be vague on other things, but I have looked at other languages that could theoretically be used out of locale, and how these match up with the places these are used, like, is that language used there, and en-US is totally in a category of its own in terms of out of locale use. It genuinely is a special case, and I apologize that I don’t have actual numbers for uk english or French or Spanish, which I looked at but that I couldn’t get cleared for publication.

SFC: It sounds like HSI is saying that the proposal to generalize the solution comes from the sake of wanting to generalize the solution, without a specific user or use case. But this isn't the case. For example, my team at google spends a lot of time on the numbering system problems, and we’ve gotten into many situations where half the users want one thing and half the other, so there’s that, generalizing to numbering system isn’t necessarily because we can generalize. The second issue I have with the approach of relying on bug reports is that there’s so many times that users don’t file bug support – someone who uses en-US and wants standard measures are more likely to file bug reports, because they know English. We don’t want to prioritize users who use English in that way. We don’t find issues related to, for example, Maori. This might not be the best example, since most Maori users also know English. But basically, bug reports aren’t the only signal. It’s a signal that there’s a problem, the problem is that CLDR’s model of locales is not right, and the solution to that is how can we leverage these CLDR models better. 

EAO: Actually here's an issue for Maori: https://bugzilla.mozilla.org/show_bug.cgi?id=1681286

HSI: one way of finding signals about whether users flip these prefs and what prefs are in demand, one is to look at what OSes offer to users. MacOS offers the most control, GNOME only offers 12/24 hour clock, even though much of this has come through Android, last I checked Android doesn’t itself, or Android’s native apps, offer this control. I haven’t checked in recent months. Of course it could be that users have needs that OS vendors aren’t addressing, but it would be more convincing that we should be exposing some of this control to the Web if this were universally across the popular operating systems across prefs. I don’t expect to get this data, but it would be interesting to know how much users adjust those prefs on MacOS that has the broader set of these controls. 

EAO: Regarding the identifier for what locale code to use to trigger for this, the original pitch is for en-ZZ because we believe it’s the most web compatible thing that wouldn’t block other implementations that could solve other problems for other locales. The other we pitched was en-US-u-rg-001zz, which goes a bit in the other end, if we are willing to consider the web compatibility of something like that, we should also test the webcompat of using en-001 as an identifier for the behavior we want. I’m aware it has a current definition in Unicode that doesn’t match what we’re looking for, but it is something to consider if en-ZZ doesn’t work for some reason. 

HSI: I expect that en-001, the semantics using UK spelling, is too entrenched from CLDR to Windows and so forth. We can't switch users from the US english UI strings to British looking UI strings, in terms of browser inference. Making that change as “browser infers what users want” would cause problems for people who actually do want the US spelling. 

### Normative: Make Intl.PluralRules ResolvePlural and associated AOs take Intl mathematical values rather than Numbers #1026

https://github.com/tc39/ecma402/pull/1026

BAN: This was an oversight. PluralRules should have used Intl mathematical values. The effect is that users should be able to use BigInt with PluralRules.

SFC: Sounds good in principle. I don't know if it has a direct impact on behaviour, given that PluralRules only care about the range of the number anyway. Does calling ToNumber on a BigInt just truncate?

BAN: ToNumber throws on BigInts.

SFC: So that is the thing that actually changes. This case no longer throws an exception. We are also preserving the extra precision in strings.

EAO: My proposal does not depend on this one, although I can't remember what exactly I did to make PluralRules work as well. I would be happy for this to land. After a quick check, this is a subset of the changes in Intl Keep Trailing Zeros.

SFC: I'm happy with TG2 approval.

RGN: +1

EAO: +1 

YSZ: +1

TG2 approves

### Normative: Increase limits on Intl MV and explicitly limit significant digits #1022

https://github.com/tc39/ecma402/pull/1022

SFC: We discussed this at length last month, but did not yet ask for TG2 approval. I brought it to TG3 and we discussed it. The notes from TG3, as part of the TG1 agenda item for this topic, I intend to put together some slides to discuss the general issue of whether we should have spec-defined limits (lower bound, upper and lower bound, whether they should be the same), RGN had good feedback on that, as did MM, I plan to bring this up in the context of the presentation on this pull request. In the meantime, do we want to have that discussion first with TG1, should I – I’m not in a hurry to land 1022, this is a problem that WH had raised, but I guess one thing that I should ask from this group is whether we approve of the PR in its current form, or if we’d approve changing it as the result of feedback. So approval 1 is do we approve on adjusting the limits, approval 2 is if we approve these limits or if we approve whatever tweaks TG1 wants to make. As a reminder, the constraints I currently have in this PR – I think EAO points out that this increases the number of digits by a factor of 100, so one thing I might change in this PR before TG1 meeting, should have done before today, maybe making the limits a little more constrictive – bigger than they currently are, but maybe a bound of 500. Right now there’s an effective bound of 408, and keep the exponents from -1000 to +1000. Making the limits bigger, but not so much bigger. Is this too big for Moddable? I’ve asked, but haven’t gotten a response.

EAO: I’m happy for us to take this to TG1 and see if they respond there.

JMN: +1, especially with discussions about Amount and Decimal in the pipeline.

SFC: Does that mean we want to bring this to TG1 – I’m trying to figure out what to give as the conclusion, since there’s TG2 uncertainty of what the bounds should be, is the approval for increasing the limits. If so, that’s enough to go to

EAO: That sounds fine to me

BAN: +1

JMN: +1

### Add an overflow option that rejects on lunisolar leap months in common years #36

https://github.com/js-temporal/proposal-temporal-v2/issues/36

SFC: I filed this issue because it’s something that came up in the context of era + monthCode, because it’s a behavior choice we have to make and I wanted to make sure that we’re aligned on what the behavior we want is. We went to 2.7 with the behavior as described in this issue. I think this table describes the situation. It only impacts Hebrew and Chinese, and the question is if we have a date like this. If you have a date in a leap year, say you’re in Adar, and you add a year to it, what do you get? There are two choices: if you have this date in Adar I and you add a year, do you get a date in Adar or an error, since Adar I doesn’t technically exist in the year that follows it. In general there’s a good article I’ve found, and I’ve asked around among Israeli colleagues, 

SFC: You will always get a RangeError when adding a year to Adar I when Overflow: reject if the day doesn’t exist in the month you’re projecting into. But what if the day exists, but not the month? PCO’s original PR used the slightly more strict behavior, I think we should have slightly more permissive behavior, I’ve asked Israeli colleagues and gotten ambiguous answers, but we must nevertheless make a choice. My thought is that this is not a situation people will have thought about when using overflow: reject, and so therefore the behavior for overflow: reject should be lenient if a lunisolar calendar is used. But I wanted to double-check if we wanted to do the stricter thing.

FYT: What about minus 1 year? When you subtract one year from the previous non-leap year, to a leap year, what do we do with that?

SFC: Going into a leap year always succeeds, the issue is going from a common year to a leap year.

FYT: not just that, if you subtract one year from a common year – let’s say Chinese calendar, let’s say year 1, you have July and leap-July. Next year, year 2, you have a July, does that go into the leap-July or July. If you count twelve months back you fall into leap-July. I’m not saying one way is correct or not, but it should be specified so that there’s a non-ambiguous meaning fo that. 

RGN: I believe this is specified, and for a lunisolar calendar 1 year is not interchangeable with 12 months. 

SFC: Yes, and we did some work to specify that case in era + monthCode (?)

HSI: In era monthcode there is a table that says that leap to common month transformation is backwards for Chinese and Dangi and forward for Hebrew. Is this based on cultural conventions, if you have a birthday anchor to a month and day in Chinese/Dangi, do they always skip backwards, in Hebrew calendar what do people use and do they always do the same kind of skipping that happens to be the other direction.

SFC: in era monthcode we did research into each of these questions and that’s how we ended up with what’s shown, the constrain behavior is when you’re constructing date from fields, and it also gets applied when doing the arithmetic, though when doing arithmetic we can have overflow: constrain be more lenient.

HSI: But you assume that the developer has thought of some things but not others. Reject, trying to reason from what English word the API uses, is suggestive of rejecting things that don’t map directly. Reject already suggests that you’re doing the thing that strict does – so how well is this established that reject needs to do the less-strict thing – not actually rejecting everything that it could potentially reject? Do we really need the three things here instead of updating reject for the behavior that now is used by strict. How well is it established that reject can’t reject all the cases that strict would reject?

EAO: Looking at the intl era monthcode proposal, where I understand this difference would really show up, what I see is there’s the NonISODateAdd AO that says “please roughly do this thing”, and [] that is more directive. But most existing things that I assume things would look like if PR 69 is approved, [?]
So I’m not sure I understand the premise: if you have overflow: reject and you do an add, you end up not throwing an error? I don’t see how you don’t throw an error when you’re doing that.

PCO: I don’t have that strong of an opinion of this, but my original intuition while I was looking at nonISODateAdd agrees with HSI. It seems like – I don’t personally see the distinction between rejecting when you land on a nonexistent day and rejecting when you add on a nonexistent month. Take that as a data point, for what that’s worth.

SFC: To answer the question from EAO, in NonISODateAdd we always call ConstrainMonthCode with constrain, we don’t pass the overflow option. If we wanted to do the strict thing we could just pass the overflow option into the other AO

EAO: I missed that – it is honestly a little bit weird. 

SFC: I brought this up is because my initial kneejerk reaction is that reject specifically refers to rejecting nonexistent days, not months, but — for the default behavior my position that people wouldn’t think about this with lunisolar, the fact that the developers are explicitly selecting this strict behavior, then it’s fine to make the change. (?)

EAO: I think we have to have the strict behavior be properly strict, and also complain if the month doesn’t exist. If we do the looser thing and allow that, it becomes a webcompat issue to later make the strict thing more strict. This is such a corner case that we could and should start out by being more strict, and then figure out later if we want to fix that.

SFC: I tend to agree with that. So this is then a normative change against the era month code proposal, since we got 2.7 with the other behaviour. We should just do a one-line pull request and put it in a 2.7 update, or in a stage 3 update, it’s not urgent, but we should make sure that’s reflected. PCO, are you interested in making that change, or do you want me to do that?

PCO: I’ll have to check with project management. 

SFC: I’m also happy to do that.

PCO: The time goes into preparing slides – I’ll have to check if I have time to do that before tomorrow. 

SFC: If you don’t get to it before tomorrow we can just hold it for the next TG1 meeting, that’s fine. If we have an open PR and we make sure the tests reflect this behavior, it’s not urgent that it gets done in September, though it would be nice since one engine is already shipping and we want to make sure that the spec is up to date with the behavior we expect.
 
### Allow engines to ship data for locales in Accept-Language #1010

https://github.com/tc39/ecma402/issues/1010

SFC: I had discussions with at the web engines hackfest in a way to add more languages in a way that doesn’t increase the fingerprint. One option that seems like it could work would be – if you set your Accept-Language to Maori, then the browser can make Maori available to websites, but _only_ if you select Maori in Accept-Language. It’s fingerprint-neutral, because you’re already indicating that you want Maori. We can discuss this in more detail next month, but since we have HSI on the call, I wanted to 

### Editorial: Simplify NumberFormat #978

https://github.com/tc39/ecma402/pull/978

SFC: We previously discussed this a few times. RGN, you had said that you wanted to look at the behavior of the spec. Do you want to look at it now, or bring it to the next meeting?

RGN: I can very easily – can I share locally, would that suffice?

RGN: So all the changes are in NumberFormat, and we’re looking at the table for Intl.NumberFormat rounding modes, and currently we have [shows one table, shows another table]. So we introduce the Negation column, and everything else remains the same. Ciel and floor are a pair, halfCeil and halfFloor are a pair, everything else is its own negation.

RGN: Next major change is going to be adding a note explaining that. Next substantial change is in FormatNumericToString, which is going to drop off into these ToRawPrecision and ToRawFixed AOs. Currently 

SFC: Previously you passed in the unsigned rounding mode, now you’re passing in the pair of rounding mode and sign. 

RGN: We can jump into ToRawFixed without loss of generality. ApplyUnsignedRoundingMode is how it works now, and it will still be how it is except we pass in sign. Let me make sure we’re not missing anything. We’ll come back to GetUnsignedRoundingMode

RGN: So ApplyUnsignedRoundingMode really – is this already taking place in the converted space?

SFC: It operates on absolute values.

RGN: We should probably make that clear, but it doesn’t matter in this case because we explicitly pass in the sign. When sign is negative, we want to put in the negation. The fact that we’re dealing with absolute values is less relevant, and less context to carry around because we have this explicit sign, and it will do the inverted behavior on the basis of that. 

RGN: FormatNumericToString likewise has this use of sign. Ah, yes, this is the table that’s collapsed in. Conversion from signed to unsigned rounding mode is far from where we started. Table 27 is defining the rounding modes, it has no concept of the relation between them or the concept of negation, and it’s not until you get down to table 29, skipping over many subsections, that you actually see the relationship between them. But even then it’s not pairing up ceil and floor – you have to infer that.  When you look at FormatNumericToString, having already passed in sign you only have to refer to one single table. That’s what we’ve accomplished in this PR. So we go from two tables and the GetUnsignedRoundingMode operation using the second one, to just everything in one place, and we do that by carrying down the sign input rather than having this GetUnsignedRoundingMode operation bounce it into an analogous space to what we’re looking at here. So, having recreated all the context over the course of the past ten minutes, what we’re really doing is taking Table 29 and its containing operation and merging it into Table 27. I’m still in favor, I like explicitly showing this crosswise pairing, I like being able to reference it, I like explaining by means of a table by note that it’s not necessary for the ones based on expansion and truncation, and I think that’s worth propagating the explicit sign signal, especially given that we’re not even noting the absolute value calculations in whichever operation it was. I know you were vocal on taking a stance on it, and thoughts from you and everyone else with whatever time we have.

SFC: Regarding this, I see where you’re coming from but I – my position on this has been that the concept of an unsigned rounding mode is a useful concept, since I feel that one of the jobs of the spec is to make it easy – to guide implementations to figure out what their APIs should be in a library, and in ICU4X we use rounding mode because it’s a useful abstraction to have. I see your thought is that it’s nice to have it in a separate table. Basically what we’re doing here is merging the table, but in the spec passing down the unsigned rounding mode but computing it based on this table instead of based on the other table. You could still pass down unsigned rounding mode where it’s one of five strings instead of one of eight strings. It still merges the tables, it just does the sign resolution in a different place.

RGN: Concretely, I think you’d be talking about a different name for the Negation column, and probably having it fully populated.

SFC: I think you can keep it the same. Let’s start from a clean slate and see what my idea of a change would be. The change would be to add the column exactly as you’ve written it to table 27, change GetUnsignedRoundingMode and have it use Table 27, and instead of returning an enum it would return one of five strings. It would read from table 27 instead of 29, and return a string instead of an enum.

RGN: That operation is only called from FormatNumericToString. It is called to take in the rounding mode from the NumberFormat instance along with the sign to produce an enum, or we say it’s producing a string. FormatNumericToString in this conception doesn’t need it, because we are propagating the string…

EAO: Am I correct in assuming that this table and a lot of this code will need to move from 402 to 262 to make a lot of these changes, given that Amount is using the same rounding modes that we’re only using in 402. Since Amount is 262, rounding modes should be in 262 as well. There’s a whole bunch of things that need to be copied at least as part of the Amount spec, since it’s doing essentially the string intl mathematical value parsing, and my understanding of our intent here is that so we can make it so that the bits of text that we need for Amount that are in 402 can be moved, possibly modified on the way, to 262, with the references in 402 updated. I don’t know if that has bearing to editorial changes made to the text at this moment.

RGN: I was thinking the same thing. This is the equivalent to the AO in Amount, it’s called ApplyRoundingModeToPositive, in this case it’s not converting but it is producing the same result.

EAO: We should make sure that there’s only one AO that both Amount and NumberFormat end up using. There’s a bit of other number parsing definitions, like the way that string intl mathematical value rules are something that’s already part of 262, we’re going to eventually merge those into one that’s used in both 262 and 402.

SFC: Does my version of this make sense to you?

RGN: I think so

SFC: Is there are reason you think it’s better to propagate sign and rounding mode all the way to the bottom? You could actually split this into two disjoint changes. Like I’ve done with intl era month code, I’ve got the change but I’m splitting it off into smaller changes. There appear to actually be two changes: merging Table 27 and 29, and then the other change is passing down the pair of sign and rounding mode. 

RGN: I would characterize the second change as “get rid of this single-use operation”, and in fact having merged the tables this single-use single-line operation still goes away, it just–

SFC: If there’s exactly one callsite for GetUnsignedRoundingMode, I’d be okay with you inlining it, only because it has exactly one call site. 

RGN: At which point we merge the tables, inline the operation, unsignedRoundingMode is just a table lookup, sends it down to ApplyUnsignedRoundingMode, which operates on non-negative mathematical values and therefore is fine. Make sense? It’s functionally equivalent, I don’t have strong feelings about it.

SFC: GetUnsignedRoundingMode, I’m on the fence if we should merge it down, it’s still an atomic operation, it’s easier – it keeps this AO a little smaller, the call site, and I do think we have a benefit of making smaller operations even if they seem trivial, so that it allows a library to say we’re implementing this function.

RGN: In terms of the spec, it just does a lookup. 

SFC: there’s three changes: 1) merge tables, 2) inline the AO (only after tables merged), 3) do the computation of the unsigned rounding mode farther down the stack, requiring passing the pair of arguments.

RGN: If we do the first two, I wouldn’t be pursuing the third anyway, since it’s all moving into 262 as EAO noted. I don’t think there’s a big enough difference between map to unsigned and pass down the resulting mode vs pass down the signed mode with the sign boolean, if we have already merged the tables and inlined the operation. Here it does the third because it didn’t follow the same sequence.

SFC: If I did the version where you have three changes, I agree with you on the first, you see no reason to do the third, change the arguments, the second one, I lean toward keeping an AO but I don’t feel strongly about that, and you lean toward inlining the AO

RGN: To share why, I agree with you that having AOs provide a benefit, even if small, but there’s a tradeoff in terms of complexity in comprehending the spec, and when there’s a big jump there’s benefit to inlining if I don’t have to think about this and what it’s supposed to do if I can just see the steps. It’s just a value judgement. In this case my preference is to have it inlined, since it helps me and possibly others to understand what FormatNumericToString is doing. It’s also true here when it’s getting the original sign, when it’s calculating the sign and passing it down, as opposed to doing the mapping, but doing the mapping is also fine. What’s detrimental is this jump out to do a table lookup. It’s indirection that doesn’t carry its weight.

SFC: basically I’m saying that if you inline the table lookup you can inline it into step 3, which is a nice benefit. The place where we change the sign is the same place as we change the rounding mode to be the other one, which is nice. It’s nice enough for me to buy into it.

RGN: It’s better, in the sense that it just gets to do it. When sign is negative you take the absolute value and also do the mapping.

SFC: And you don’t need to do it in the positive case.

RGN: This has the same result because it’s only setting sign and not doing it down there. I agree that it’s even better to add another step to 1.3.c. Given that these are splittable, would it be better for you in separate PRs or sequential commits in same PR?

SFC: Which is splittable?

RGN: Expanding the table vs inlining the rounding mode change.

SFC: I have a slight preference to make commits to two PRs, just to have two commits for posterity. 

RGN: For the record, when a PR has semantically meaningful commits, I’ve tended to preserve them in the merge to main. They’re definitely separate commits, the question is that are they separate PRs. Keeping it in one is fine. 



